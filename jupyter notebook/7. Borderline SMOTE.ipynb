{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fec0a73-f17e-4078-a077-8e7980cb30ff",
   "metadata": {},
   "source": [
    "## Borderline SMOTE\n",
    "\n",
    "Here we will use Borderline SMOTE which is an extension of SMOTE to balance the classes and then will move forward with the modeling section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b482b1f-8223-4670-8a0f-314f52e80c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51ff822b-6737-42b5-a7cc-55a3d63df287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ankle_acc_hor_forward</th>\n",
       "      <th>ankle_acc_ver</th>\n",
       "      <th>ankle_acc_hor_lateral</th>\n",
       "      <th>upper_leg_acc_hor_forward</th>\n",
       "      <th>upper_leg_acc_ver</th>\n",
       "      <th>upper_leg_acc_hor_lateral</th>\n",
       "      <th>trunk_acc_hor_forward</th>\n",
       "      <th>trunk_acc_ver</th>\n",
       "      <th>trunk_acc_hor_lateral</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-40</td>\n",
       "      <td>970</td>\n",
       "      <td>326</td>\n",
       "      <td>-36</td>\n",
       "      <td>962</td>\n",
       "      <td>242</td>\n",
       "      <td>320</td>\n",
       "      <td>657</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-60</td>\n",
       "      <td>990</td>\n",
       "      <td>316</td>\n",
       "      <td>54</td>\n",
       "      <td>953</td>\n",
       "      <td>262</td>\n",
       "      <td>77</td>\n",
       "      <td>914</td>\n",
       "      <td>446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-111</td>\n",
       "      <td>980</td>\n",
       "      <td>346</td>\n",
       "      <td>-27</td>\n",
       "      <td>953</td>\n",
       "      <td>262</td>\n",
       "      <td>-48</td>\n",
       "      <td>857</td>\n",
       "      <td>446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-111</td>\n",
       "      <td>980</td>\n",
       "      <td>346</td>\n",
       "      <td>36</td>\n",
       "      <td>981</td>\n",
       "      <td>232</td>\n",
       "      <td>-38</td>\n",
       "      <td>800</td>\n",
       "      <td>446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-60</td>\n",
       "      <td>1009</td>\n",
       "      <td>346</td>\n",
       "      <td>18</td>\n",
       "      <td>972</td>\n",
       "      <td>242</td>\n",
       "      <td>77</td>\n",
       "      <td>866</td>\n",
       "      <td>436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021876</th>\n",
       "      <td>-212</td>\n",
       "      <td>1000</td>\n",
       "      <td>376</td>\n",
       "      <td>690</td>\n",
       "      <td>-166</td>\n",
       "      <td>282</td>\n",
       "      <td>77</td>\n",
       "      <td>942</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021877</th>\n",
       "      <td>-232</td>\n",
       "      <td>970</td>\n",
       "      <td>356</td>\n",
       "      <td>572</td>\n",
       "      <td>-55</td>\n",
       "      <td>10</td>\n",
       "      <td>67</td>\n",
       "      <td>961</td>\n",
       "      <td>339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021878</th>\n",
       "      <td>-232</td>\n",
       "      <td>970</td>\n",
       "      <td>356</td>\n",
       "      <td>272</td>\n",
       "      <td>92</td>\n",
       "      <td>-70</td>\n",
       "      <td>97</td>\n",
       "      <td>961</td>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021879</th>\n",
       "      <td>-252</td>\n",
       "      <td>921</td>\n",
       "      <td>346</td>\n",
       "      <td>354</td>\n",
       "      <td>18</td>\n",
       "      <td>-171</td>\n",
       "      <td>87</td>\n",
       "      <td>952</td>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021880</th>\n",
       "      <td>-232</td>\n",
       "      <td>862</td>\n",
       "      <td>366</td>\n",
       "      <td>390</td>\n",
       "      <td>111</td>\n",
       "      <td>-191</td>\n",
       "      <td>87</td>\n",
       "      <td>952</td>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021881 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ankle_acc_hor_forward  ankle_acc_ver  ankle_acc_hor_lateral  \\\n",
       "0                          -40            970                    326   \n",
       "1                          -60            990                    316   \n",
       "2                         -111            980                    346   \n",
       "3                         -111            980                    346   \n",
       "4                          -60           1009                    346   \n",
       "...                        ...            ...                    ...   \n",
       "1021876                   -212           1000                    376   \n",
       "1021877                   -232            970                    356   \n",
       "1021878                   -232            970                    356   \n",
       "1021879                   -252            921                    346   \n",
       "1021880                   -232            862                    366   \n",
       "\n",
       "         upper_leg_acc_hor_forward  upper_leg_acc_ver  \\\n",
       "0                              -36                962   \n",
       "1                               54                953   \n",
       "2                              -27                953   \n",
       "3                               36                981   \n",
       "4                               18                972   \n",
       "...                            ...                ...   \n",
       "1021876                        690               -166   \n",
       "1021877                        572                -55   \n",
       "1021878                        272                 92   \n",
       "1021879                        354                 18   \n",
       "1021880                        390                111   \n",
       "\n",
       "         upper_leg_acc_hor_lateral  trunk_acc_hor_forward  trunk_acc_ver  \\\n",
       "0                              242                    320            657   \n",
       "1                              262                     77            914   \n",
       "2                              262                    -48            857   \n",
       "3                              232                    -38            800   \n",
       "4                              242                     77            866   \n",
       "...                            ...                    ...            ...   \n",
       "1021876                        282                     77            942   \n",
       "1021877                         10                     67            961   \n",
       "1021878                        -70                     97            961   \n",
       "1021879                       -171                     87            952   \n",
       "1021880                       -191                     87            952   \n",
       "\n",
       "         trunk_acc_hor_lateral  annotation  \n",
       "0                          349           0  \n",
       "1                          446           0  \n",
       "2                          446           0  \n",
       "3                          446           0  \n",
       "4                          436           0  \n",
       "...                        ...         ...  \n",
       "1021876                    349           1  \n",
       "1021877                    339           1  \n",
       "1021878                    359           1  \n",
       "1021879                    359           1  \n",
       "1021880                    368           1  \n",
       "\n",
       "[1021881 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/merged.csv\")\n",
    "df.drop(columns=[\"Time(ms)\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93028336-bc8e-450d-9c6d-fc807d58983e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='annotation', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'annotation', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee5285f4-f4fd-44b5-a9e3-a5d0c3c6382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"annotation\"])\n",
    "y = df[\"annotation\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n",
    "bsmote = BorderlineSMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = bsmote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b04dd3aa-c00d-4ba2-84cc-eb20b2842468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    524990\n",
       "1    524990\n",
       "0    524990\n",
       "Name: annotation, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "378414b5-e15c-4062-8300-3ef8d81b392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dev\\anaconda3\\lib\\site-packages\\xgboost\\core.py:430: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dev\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:35:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[ 46115  11094    754]\n",
      " [ 11957 112930   6254]\n",
      " [   458   8754   6061]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79     57963\n",
      "           1       0.85      0.86      0.86    131141\n",
      "           2       0.46      0.40      0.43     15273\n",
      "\n",
      "    accuracy                           0.81    204377\n",
      "   macro avg       0.70      0.68      0.69    204377\n",
      "weighted avg       0.80      0.81      0.81    204377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': 500,\n",
    "    'learning_rate': 0.01,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3\n",
    "}\n",
    "xgb = XGBClassifier(params)\n",
    "xgb.fit(x_train_resampled, y_train_resampled)\n",
    "y_pred = xgb.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9edcdbe-d8a1-405c-8795-c86bb3f41352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 47353   8797   1813]\n",
      " [ 11797 108429  10915]\n",
      " [  1568   6132   7573]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80     57963\n",
      "           1       0.88      0.83      0.85    131141\n",
      "           2       0.37      0.50      0.43     15273\n",
      "\n",
      "    accuracy                           0.80    204377\n",
      "   macro avg       0.68      0.71      0.69    204377\n",
      "weighted avg       0.81      0.80      0.80    204377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(x_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78d14c36-0db2-44e2-92aa-7fa687a56e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50809   6004   1150]\n",
      " [  9474 113296   8371]\n",
      " [   885   5620   8768]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85     57963\n",
      "           1       0.91      0.86      0.88    131141\n",
      "           2       0.48      0.57      0.52     15273\n",
      "\n",
      "    accuracy                           0.85    204377\n",
      "   macro avg       0.74      0.77      0.75    204377\n",
      "weighted avg       0.85      0.85      0.85    204377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(x_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af8f701b-8556-4bbf-8aa6-b8b62ed960a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50706   6084   1173]\n",
      " [  6774 115856   8511]\n",
      " [   522   4708  10043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87     57963\n",
      "           1       0.91      0.88      0.90    131141\n",
      "           2       0.51      0.66      0.57     15273\n",
      "\n",
      "    accuracy                           0.86    204377\n",
      "   macro avg       0.77      0.81      0.78    204377\n",
      "weighted avg       0.87      0.86      0.87    204377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(x_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1e59701-01ca-49a1-a59c-cd5e91283edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50700   6087   1176]\n",
      " [  6603 116079   8459]\n",
      " [   504   4677  10092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88     57963\n",
      "           1       0.92      0.89      0.90    131141\n",
      "           2       0.51      0.66      0.58     15273\n",
      "\n",
      "    accuracy                           0.87    204377\n",
      "   macro avg       0.77      0.81      0.78    204377\n",
      "weighted avg       0.87      0.87      0.87    204377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(x_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "131fa0d2-fad1-4686-8b83-068319805edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/model_rf.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, '../model/model_rf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c11237-e308-4615-bc76-9f5ec2178d4b",
   "metadata": {},
   "source": [
    "## Interpretation of the above experiment \n",
    "\n",
    "We used Borderline SMOTE to oversample the training dataset so that the classes become balanced. After that we experimented with XGBoost, Decision Tree and Random Forest. From the experiments we found that the random forest model is the most stable one with precision and recall of the annotation 2 class being 51% and 66% respectively and the overall accuracy being 87%.\n",
    "\n",
    "Now from here we can fine tune the model hyperparameters using GridSearchCV so as to increase the performance and the stability of the model. Due to time constraint here we will not be going forward with the GridSearchCV technique.\n",
    "\n",
    "After that we will move to the deployment section where we will just display a basic deployment scenario showing the probability of freeze."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
